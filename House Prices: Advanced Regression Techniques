import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn import linear_model
from sklearn import metrics

train = pd.read_csv('/Machine-Learning/all/train.csv')
test = pd.read_csv('/Machine-Learning/all/test.csv')
先整体查看下数据sns.distplot(train['SalePrice'])train['SalePrice'].describe()


count      1460.000000
mean     180921.195890
std       79442.502883
min       34900.000000
25%      129975.000000
50%      163000.000000
75%      214000.000000
max      755000.000000
Name: SalePrice, dtype: float64

---

#skewness and kurtosis
print("偏度: %f" % train['SalePrice'].skew())
print("峰度: %f" % train['SalePrice'].kurt())


偏度: 1.882876
峰度: 6.536282偏度能够反应分布的对称情况，右偏（也叫正偏），在图像上表现为数据右边脱了一个长长的尾巴，这时大多数值分布在左侧，有一小部分值分布在右侧。峰度反应的是图像的尖锐程度：峰度越大，表现在图像上面是中心点越尖锐。在相同方差的情况下，中间一大部分的值方差都很小，为了达到和正太分布方差相同的目的，必须有一些值离中心点越远，所以这就是所说的“厚尾”，反应的是异常点增多这一现象。查看热图data = train.corr()
sns.heatmap(data)越是白色越是关联紧密。可以观察SalePrice跟哪些属性关联更紧密。直接查看热力图显示有很多时候显示不全，尤其属性特别多的时候。这个时候，可能直接查看更方便data['SalePrice'].sort_values()

KitchenAbvGr    -0.135907
EnclosedPorch   -0.128578
MSSubClass      -0.084284
OverallCond     -0.077856
YrSold          -0.028923
LowQualFinSF    -0.025606
Id              -0.021917
MiscVal         -0.021190
BsmtHalfBath    -0.016844
BsmtFinSF2      -0.011378
3SsnPorch        0.044584
MoSold           0.046432
PoolArea         0.092404
ScreenPorch      0.111447
BedroomAbvGr     0.168213
BsmtUnfSF        0.214479
BsmtFullBath     0.227122
LotArea          0.263843
HalfBath         0.284108
OpenPorchSF      0.315856
2ndFlrSF         0.319334
WoodDeckSF       0.324413
LotFrontage      0.351799
BsmtFinSF1       0.386420
Fireplaces       0.466929
MasVnrArea       0.477493
GarageYrBlt      0.486362
YearRemodAdd     0.507101
YearBuilt        0.522897
TotRmsAbvGrd     0.533723
FullBath         0.560664
1stFlrSF         0.605852
TotalBsmtSF      0.613581
GarageArea       0.623431
GarageCars       0.640409
GrLivArea        0.708624
OverallQual      0.790982
SalePrice        1.000000
Name: SalePrice, dtype: float64可以看到有不少值是负的，还有很多值低于0.2，我们可以直接把这些feature从我们的模型里面去掉。数据处理处理异常数据sns.lmplot(x='GrLivArea', y='SalePrice', data=train, fit_reg=False, scatter=True)可以看到有两个面积特别大的房子，售价却很低。故我们在训练数据中删除这两个数据。train = train[-((train.SalePrice < 200000) &  (train.GrLivArea > 4000))]缺失数据的处理查看缺失数据for col in train.columns:
    if train[col].isnull().sum() > 0:
        print(col, train[col].isnull().sum())


LotFrontage 259
Alley 1367
MasVnrType 8
MasVnrArea 8
BsmtQual 37
BsmtCond 37
BsmtExposure 38
BsmtFinType1 37
BsmtFinType2 38
Electrical 1
FireplaceQu 690
GarageType 81
GarageYrBlt 81
GarageFinish 81
GarageQual 81
GarageCond 81
PoolQC 1452
Fence 1177
MiscFeature 1404处理缺失数据#一半是删除过多空值的属性，一半是删除无关联的属性 
train = train.drop(["MiscFeature", "Id", "PoolQC", "Alley", "Fence","GarageFinish", "KitchenAbvGr", "EnclosedPorch", "MSSubClass", "OverallCond", "YrSold", "LowQualFinSF", "MiscVal", "BsmtHalfBath", "BsmtFinSF2", "3SsnPorch", "MoSold", "PoolArea"], axis=1)

test = test.drop(["MiscFeature", "PoolQC", "Alley", "Fence","GarageFinish", "KitchenAbvGr", "EnclosedPorch", "MSSubClass", "OverallCond", "YrSold", "LowQualFinSF", "MiscVal", "BsmtHalfBath", "BsmtFinSF2", "3SsnPorch", "MoSold", "PoolArea"], axis=1)

#汇总train和test的数据
all_data = pd.concat((train, test))
#如果数字，填写均值。如果字符串，填写次数最多的
for col in train.columns:
    if train[col].isnull().sum() > 0:
        if train[col].dtypes == 'object':
            val = all_data[col].dropna().value_counts().idxmax()
            train[col] = train[col].fillna(val)
        else:
            val = all_data[col].dropna().mean()
            train[col] = train[col].fillna(val)

for col in test.columns:
    if test[col].isnull().sum() > 0:
        if test[col].dtypes == 'object':
            val = all_data[col].dropna().value_counts().idxmax()
            test[col] = test[col].fillna(val)
        else:
            val = all_data[col].dropna().mean()
            test[col] = test[col].fillna(val)转非数对非数字的属性进行转换。这里我使用最简单粗暴的get_dummies()来对train数据和test数据进行转换。这里也有个地方要注意：test数据里面属性的取值范围可能跟train数据里面属性的取值范围部分不同。这样如果直接对test数据和train数据做get_dummies，很可能会导致test和train数据转化后出现了不同的列。所以需要综合处理。#综合处理，转值类型
for col in all_data.select_dtypes(include = [object]).columns:
    train[col] = train[col].astype('category', categories = all_data[col].dropna().unique())
    test[col] = test[col].astype('category', categories = all_data[col].dropna().unique())

for col in train.columns:
    if train[col].dtype.name == 'category':
        tmp = pd.get_dummies(train[col], prefix = col)
        train = train.join(tmp)
        train = train.drop(col, axis=1)

for col in test.columns:
    if test[col].dtype.name == 'category':
        tmp = pd.get_dummies(test[col], prefix = col)
        test = test.join(tmp)
        test = test.drop(col, axis=1)建模&&预测lr = linear_model.LinearRegression()
X = train.drop("SalePrice", axis=1)
y = np.log(train["SalePrice"])

lr = lr.fit(X, y)
results = lr.predict(test.drop("Id", axis = 1))
final = np.exp(results)

submission = pd.DataFrame()
submission['Id'] = test.Id
submission['SalePrice'] = final

submission.head()
Id  SalePrice
0   1461    121738.894467
1   1462    160600.237304
2   1463    186313.100909
3   1464    197581.617513
4   1465    198611.414415
submission.to_csv("submission1.csv", index= False)
